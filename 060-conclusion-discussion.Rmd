# Conclusion and discussion {#discussion}

We've introduced a general-purpose high-dimensional multivariate simulation algorithm and provide a high-performance implementation called [`bigsimr`](https://schisslergroup.github.io/bigsimr/). 
The high-performance --- efficient, multi-core and GPU enabled --- algorithms and software provide 
The random vector generation method is largely inspired by NORTA (@Cario1997) and Gaussian copula-based approaches (@MB13, @BF17, @Xia17).
The major contributions of our work presented here involve high-dimensional scalability, model flexibility, and high-performance implementation with broad potential data analytic applications for modern big data challenges.

It is usually customary to compare new tools and algorthms directly to existing competing methods.
In our MC studies, however, we only employ our proposed methodology, since our previous work has show that existing tools are simply not designed or feasible to meet our HD goal (see @Li2019gpu for evalutions of the `R` `copula`package and others). 
For the bivariate simulations, existing packages such as [`nortaRA`](https://github.com/cran/NORTARA/blob/master/inst/doc/NORTARA.R) work well to match Pearson correlations exactly.

<!-- 
We advocate the use of Kendall's $\tau$ as it better captures correlation among components of non-normal, as well as non-linear patterns of association.
Moreover, the matching Kendall's $\tau$ is nearly trivial due to the invariant of monotone transformations, after an adjustment to the input correlation matrix.
-->

<!-- 
We also show utility in our methodology through an application to differential gene expression analysis from RNA-sequencing data.
The application results show that correlations indeed matter in the large-scale hypothesis testing, as many others have noted (for example, see @BE07, @Wu2012b).
We also hope that the application provides an example workflow --- and other strategy to use in simulation design.
Even the best-performing simulations we provide show a gap from the empirical distribution. To keep the demonstration straightforward, we did not attempt to match the empirical distribution of test statistics as precisely as possible. Yet our methodology could be more creatively applied to meet that goal. One could consider marginal distributions from different families, such as Poisson for a subset of genes. One could imagine finding a best fitting probability distribution among a class of distributions for each gene and this could perhaps a better fit. One could imagine additional structures/features in the data that an analyst could model to improve the correspondence with the empirical values, for example row correlations and high-dimensional covariance estimators (see @Won2013g).
-->

There are limitations to the methodology and implementation.
The most obvious missing feature the proposed methodology is the inability to match a Pearson correlation matrix exactly.
As discussed in [Algorithms](algorithms) and extensively by @XZ19, this is a computational intense procedure and not a natural choice for characterizing dependency for non-normal marginals, especially in the high-dimensional setting.
While we do not provide an implementation directly supporting Pearson matching, user can always supply their own input Pearson after using a supplementary matching scheme [@Cario1997; @XZ19].

<!-- 
Further, while we provide the ability of the user to specify discrete marginals, exact matching a desired dependency measure is not yet obtained. One potential solution for this is *rescale* to account for ties [ref]. Finally we note, that the algorithm requires invertible marginal cdfs. This gives some restriction to the available marginal probability distributions (DOES IT? FOR EXAMPLE?). 
From a practical computing standpoint, the user's computing resource provides the ultimate limit on how large a dimension can be simulated using the `bigsimr` R package. A user must consider carefully the available memory and cores when conducting a Monte Carlo experiment. 
-->

Future work includes developing scalable algorithms to match the Pearson correlation matrix more precisely, discrete-margin specific modifications including fast Spearman's correlation rescaling (see Equation \@ref(eq:spearmanRescaled)), and *bona fide* high-dimensional correlation estimation (for example, see @Won2013g).
From an implementation standpoint, `bigsimr` only supports Nvidia GPUs and refactoring the code using OpenCL would broaden the user base.
As problems grow even larger, multi-GPU support is a logical progression in this highly parallelization algorthmic scheme and warrant further development.


