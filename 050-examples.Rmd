# Example applications for our motivating data

```{r ch050-LoadLib, echo = FALSE, eval = TRUE, message=FALSE, warning=FALSE, results = "hide"}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
# reticulate::use_condaenv("bigsimr")
library(bigsimr)
library(tidyverse)
cores <- as.integer( parallel::detectCores() - 1 )
set.seed(10142020)
```

```{r ch050-preview, echo = FALSE, eval = FALSE}
bookdown::preview_chapter('050-examples.Rmd')
```

This section demonstrates how to simulate high-dimensional multivariate data using `bigsimr`, aiming to replicate the structure of high dimensional dependent count data.
In fact, simulating RNA-sequencing (RNA-seq) data is a one of the primary motivating applications of the proposed methodology, seeking scaleable Monte Carlo methods for realistic multivariate simulation (for example, see Schissler, Piegorsch, and Lussier 2018).

The RNA-seq data generating process involves counting how often a particular messenger RNA (mRNA) is expressed in a biological sample.
Since this is a counting processing with no upper bound, many modeling approaches discrete random variables with infinite support.
Often the counts exhibit over-dispersion and so the negative binomial arises as a sensible model for the expression levels (\emph{gene counts}).
Moreover, the counts are correlated (co-expressed) and cannot be assumed to behave independently.
RNA-seq platforms quantify the entire transcriptome in one experimental run, resulting in high dimensional data.
In humans, this results in count data corresponding to over 20,000 genes (coding genomic regions) or even over 77,000 isoforms when alternating spliced mRNA are counted.
	This suggests simulating high-dimensional multivariate NB with heterogeneous marginals would be useful tool in the development and evaluation of RNA-seq analytics.

## Simulating High-Dimensional RNA-seq data

In an illustration of our proposed methodology applied to real data, we seek to simulate RNA-sequencing data by producing simulated random vectors with assumed marginal distributions with estimated parameters.
Our goal is to replicate the structure of a breast cancer data set (BRCA data set from The Cancer Genome Atlas).
For simplicity of illustration, we begin by filtering to retain the top 5\% highest expressing genes of the 20,501 gene measurements from $N=1212$ patients' tumor samples, resulting in $d=1026$ genes.

<!--
All these genes exhibit over-dispersion and, so, we proceed to estimate the NB parameters $(r_i, p_i), i=1,\ldots,d$ to determine the target marginal PMFs $g_i(y_i)$ (via method of moments).
Notably, the $\hat{p}_i's$ are small --- ranging in $[3.934 \times 10^{-6} , 1.217 \times 10^{-2}]$.
To complete the simulation algorithm inputs, we estimate the Pearson correlation matrix $\bf{R_Y}$ and set that as the target correlation.
 -->

<!--
With the simulation targets specified, we proceed to simulate $N=10,000$ random vectors $\bf{Y}$ $=( Y_1,\ldots,Y_d)$ with target Pearson correlation $\bf{R_Y}$ and marginal PMFs $g_i(y_i)$ using a $\bf{T}$-Poisson hierarchy of Kind II.
Specifically, we first employ the \emph{direct Gaussian copula} approach to generate $N$ random vectors following a standard multivariate Gamma distribution $\bf{T}$ with shape parameters $r_i$ equal to the target $n_i$ and Pearson correlation matrix $\bf{R_T}$.
Care must be taken when setting the specifying $\bf{R}$ (refer to Equation \ref{gay.cop.pdf}) --- we employ Equation \ref{mix.poi.corr} to compute the scaling factors $c_{i,j}$ and adjust the underlying correlations to ultimately match the target $\bf{R_Y}$.
Notably, of the $525,825$ pairwise correlations from the $1026$ genes, no scale factor was less than $0.9907$, indicating the model can produce essentially the entire range of possible correlations.
Here we are satisfied with approximate matching of the specified Gamma correlation and set $\bf{R}$ = $\bf{R_T}$ in our Gaussian copula scheme ($\bf{R}$ indicating the specified multivariate Gaussian correlation matrix).
Finally, we generate the desired random vector $Y_i=N_i(t_i)$ by simulating Poisson counts with expected value $\mu_i=\lambda_i \times T_i$, for $i=1,\ldots,d$ (with $\lambda_i=\frac{(1-p_i)}{p_i}$) and repeat $N=10,000$ times.
-->

```{r ch050-readBRCA, echo=FALSE, eval=TRUE}
## full workflow simulating RNA-seq data
brca <- readRDS(file = 'data/brca99.rds') 
```

Let's walk through a workflow simulating RNA-seq data

```{r ch050-estRhoBRCA, echo=TRUE, eval=TRUE}
## 1. Estimate Spearman's correlation on the count data
## corType <- 'pearson'
corType <- 'spearman'
system.time( nb_Rho <- bigsimr::cor_fast( brca, method = corType ) )
```

```{r ch050-estMargins, echo = FALSE, eval = TRUE}
## 2. Estimate NegBin parameters using Method of Moments
estimateNegBinMoM <- function(tmpGene, minP = 1e-7) {
    tmpMean <- mean(tmpGene)
    tmpVar <- var(tmpGene)
    ## relate to nbinom parameters
    ## See ?rbinom for details.
    p <- tmpMean / tmpVar
    if (p < minP) {p <- minP } ## maybe add noise here
    n <- ( tmpMean * p) / ( 1  - p )  
    ## format for bigsimr margins
    return( list("nbinom", size = n, prob = p) )
}
brcaMargins <- apply( unname(as.matrix(brca)), 2, estimateNegBinMoM )
## describe the margins
probs <- unlist( lapply( brcaMargins, function(x) {x$prob} ) )
## summary(probs)
sizes <- unlist( lapply( brcaMargins, function(x) {x$size} ) )
## summary(sizes)
## head( sort( unlist( lapply( brcaMargins, function(x) {x$size} ) ) ) )
```

```{r ch050-nbHelpers}
make_nbinom_alist <- function(sizes, probs) {
  lapply(1:length(sizes), function(i) {
    substitute(qnbinom(size = s, prob = p), 
               list(s = sizes[i], p = probs[i]))
  })
}
## make_nbinom_alist(c(20, 21, 22), c(0.3, 0.4, 0.5))
nbinom_mom <- function(x) {
  m <- mean(x)
  s <- sd(x)
  s2 <- s^2
  p <- m/s2
  r <- m^2 / (s2 - m)
  c(r, p)
}
```

Now specify the desired multivariate negative binomial distribution.

```{r ch050-runBRCA, echo=TRUE, results=TRUE, cache = TRUE}
## Set the number of random vectors
n <- 10000
## construct margins
nb_margins <- make_nbinom_alist(sizes, probs)
## run sims
system.time( sim_nbinom <- rvec(n, nb_Rho, nb_margins, type = corType,
                                ensure_PSD = TRUE, cores = cores) )
colnames(sim_nbinom) <- names(brca)
```

Figure X.

```{r ch050-simDataFig, echo = FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.width= 8, fig.align='center', fig.cap='Simulated data for 3 randomly selected high-expressing genes, replicating the real data structure describing in the Introduction.'}
## retrieve the examples from an earlier chapter
## there is probably a better way to do this
exampleGenes <- readRDS(file = './data/exampleGenes.rds') 
GGally::ggpairs(data = as.data.frame(sim_nbinom[ ,exampleGenes] ))
```

Figure X shows the results of our simulation by comparing the specified target parameter (horizontal axes) with the corresponding quantities estimated from the simulated data (vertical axes).
The evaluation shows that the simulated counts approximately match the target parameters and exhibit the full range of estimated correlation from the data.
Utilizing 15 CPU threads in a MacBook Pro carrying a 2.4 GHz 8-Core Intel Core i9 processor, the simulation completed in less than 30 seconds.

```{r ch050-figBRCA, echo=F, eval=T, fig.cap="bigsimr produces simulated random vectors from a multivariate negative binomial that replicate the estimated structure from an RNA-seq data set. The dashed red lines indicated equality between estimated parameters (vertical axes; derived from the simulated data) and the specified target parameters (horizontal axes)."}
par(mfrow=c(1,3))
## estimate rho from sims and plot
nb_Rho_hat <- cor_fast(sim_nbinom, method = corType)
plot(nb_Rho[lower.tri(nb_Rho)], nb_Rho_hat[lower.tri(nb_Rho_hat)],
     xlim = c(-1, 1), ylim = c(-1, 1),
     pch = 4, cex = 1, col = rgb(0, 0, 1, 0.05),
     xlab = "Target Correlation", ylab = "Estimated Correlation",
     main = "Correlation Matching")
abline(a = 0, b = 1, col="red", lty="dashed")
## estimate prob,size from sims and plot
nbinom_size_prob_hat <- apply(sim_nbinom, 2, nbinom_mom)
plot(sizes, nbinom_size_prob_hat[1,],
     pch = 4, cex = 1, col = rgb(0, 0, 1, 1),
     xlab = "Target Size", ylab = "Estimated Size",
     main = "Marginal NB Size Matching")
abline(a=0, b=1, col="red", lty="dashed")
plot(log(probs), log(nbinom_size_prob_hat[2,]),
     pch = 4, cex = 1, col = rgb(0, 0, 1, 1),
     xlab = "Target Log Probability", ylab = "Estimated Log Probability",
     main = "Marginal NB Probability Matching")
abline(a=0, b=1, col="red", lty="dashed")
par(mfrow=c(1,1))
```

## Simulation-based UHD joint probability calculations

To conduct statistical inference, via maximum likelihood for example, a critical task is to evaluate the joint probability mass (or density) function:

$$
P( \bf{Y} = \bf{y} ), y_i \in \chi_i.
$$

where $\chi_i$ is the sample space for the $i^{th}$ component of the random vector $\bf{Y}$.
Compact representations with convenient computational forms are rare for high-dimensional constructions, especially with hetereogeneous, correlated marginal distributions (or margins of mixed data types).
Given a large number simulated vectors as produced above, estimated probabilities are readily given by counting the proportion of simulated vectors meeting the desired condition.
In our motivating application, one may ask what is the probability that all genes expressed greater than a certain threshold value $\bf{y_0}$.

Then we estimate

$$
\hat{P}( \bf{Y} >= \bf{ y_0 } ) = \sum_{b=1}^B I( \bf{Y^{(b)}} > \bf{ y_0 } ) / B
$$

where $\bf{Y^{(b)}}$ is the $b^{th}$ simulated vector in a total of $B$ simulation replicates and $I(\dot)$ is the indicator function.
For example, we can estimate from our $B=10,000$ simulated vectors the probability that all genes express more than $\bf{y_0} = 1000$.

```{r ch050-densityEvaluation, echo=TRUE, eval=TRUE}
d <- ncol(sim_nbinom)
B <- nrow(sim_nbinom)
threshold <- rep( 1000, d)
mean(apply( sim_nbinom,  1,
           function(X, y0=threshold) {
               all( X > y0) }
           ))
```

## UHD Parameteric bootstrap

Since many of the correlations are near zero, one could ask whether it is
possible that test the hypothesis that $H_0: R = R_0$.

```{r ch050-corrTest, echo=FALSE, eval=FALSE, include=FALSE}

```

