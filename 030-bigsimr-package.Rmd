# The `bigsimr` R package

The `bigsimr` package is a high-performance implementation of the proposed random vector generation algorithm and associated functions (see Section \@ref(algorithms) for details).
When designing `bigsimr`, we aimed to conveniently provide parallelized computation, through multi-core and GPU acceleration, while allowing advanced users to customize and automate workflows.

This subsections below describe the basic use of `bigsimr`, by stepping through a low-dimensional (2D) simulation workflow for the often-used example data set `airquality`.
This workflow proceeds from data, to estimation, simulation configuration, random vector generation, and result visualization.
For this low-dimensional setting, we compute using a single central processing unit (CPU) as the overhead in forking the tasks to multiple cores outweighs the computational gains. 
Then we transition to advanced use where we briefly describe some of the high-performance features and syntax.
The section concludes with a short description of how to use `bigsimr` on a computer clusters through slurm scheduling via the `rslurm` package.

<!-- 
`bigsimr` is an R package for simulating high-dimensional multivariate data with arbitrary marginal distributions. The efficiency behind generating multivariate samples comes from the ability to utilize a GPU during the generation of multivariate normal samples and the subsequent transformation to uniform samples (see section \@ref(rand-vec-gen)). A GPU is not necessary in order to use `bigsimr`, and the speed benefits generally only come when simulating very high dimensional data ($d > 10000$).

The next computational step after obtaining the correlated uniform marginals is the inverse transform into the target marginal distributions. Since this consists of $d$ independent transformations, we utilize parallelization to achieve higher throughput. As with many parallel algorithms, there is overhead associated with forking the task to utilize multiple cores, however cost is negligible compared to the total run-time.
-->

## Basic use illustrated through a minimal example

We'll demonstrate the basic use and syntax of `bigsimr` through an example workflow applied to the New York air quality data set (`airquality`) included in the R `datasets` package.
First, we load the `bigsimr` library and a few other convenient data science packages, including the syntactically-elegant `tidyverse` suite of `R` packages.

```{r ch030-basic-example-setup, echo=TRUE, message=FALSE, cache=F}
library(bigsimr)
library(tidyverse)
library(patchwork)
```

For simplicity and to provide a minimal working example, we'll consider bivariate simulation of temperature, in degrees Fahrenheit, and ozone level, in parts per billion.

```{r ch030-air-quality-data, echo=TRUE}
df <- airquality %>%
  select(Temp, Ozone) %>%
  drop_na()
```

```{r ch030-aq-glimpse}
glimpse(df)
```

Figure \@ref(fig:ch030-aq-joint-dist) visualizes the bivariate relationship between Ozone and Temperature.
We aim to simulate random two-component vectors mimicking this structure. 
The margins are not normally distributed, particularly the ozone level exhibits a strong positive skew.

```{r ch030-aq-joint-dist, echo = FALSE, eval=TRUE, message=FALSE, warning=FALSE, fig.width= 8, fig.align='center', fig.cap="Bivariate scatterplot of Ozone vs. Temperature with estimated marginal densities. The data are left skewed tails and appear to be correlation.", cache=F}

p0 <- ggplot(df, aes(Temp, Ozone)) +
  geom_point(size = 1) +
  theme(legend.position = "none") +
  labs(x = "Temperature")

pTemp <- ggplot(df, aes(Temp)) + 
  geom_density() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())

pOzone <- ggplot(df, aes(Ozone)) + 
    geom_density() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank()) +
  coord_flip()

pTemp + plot_spacer() + p0 + pOzone + 
  plot_layout(widths = c(3,1), heights = c(1, 3)) 
```

Next, we specify the marginal distributions and correlation coefficient (both its type and magnitude).
Here the analyst is free to be creative.
For this example, we will not take up goodness-of-fit considerations to determine the marginal distributions.
But it seems sensible without domain knowledge to estimate these quantities from the data and `bigsimr` contains fast functions designed for this task.

*Specifying marginal distributions*.
Based on the estimated densities in Figure \@ref(fig:ch030-aq-joint-dist), we'll assume `Temp` is normally distributed and `Ozone` is log-normally distributed since its values are positive and skewed.
We'll use the well-known, unbiased estimators for the normal distribution's parameters and maximum likelihood estimators for the log-normal parameters:

```{r ch030-aq-temp-pars, echo=TRUE, eval=TRUE}
df %>% 
  select(Temp) %>% 
  summarise_all(.funs = c(mean = mean, sd = sd))
```

```{r ch030-aq-ozone-pars, echo=TRUE}
mle_mean <- function(x) mean(log(x))
mle_sd <- function(x) mean( (log(x) - mean(log(x)))^2 )

df %>% 
  select(Ozone) %>% 
  summarise_all(.funs = c(meanlog = mle_mean, sdlog = mle_sd))
```

Next, we'll configure the input marginals for later input into `bigsimr::rvec`.
The marginal distributions are specifying using `R`'s special `alist` function.
This allows one to enter the distributions without evaluating anything (yet).

```{r ch030-margins-alist, echo=TRUE}
margins <- alist(
    qnorm(mean = 77.871, sd = 9.4855),
    qlnorm(meanlog = 3.419, sdlog = 0.7426),
)
```

Notice that we use the *quantile* function for the marginals, as that is how the marginal distributions $F_i$ enter into the `bigsimr::rvec` algorithm.
This implementation strategy supports all `R` `base` probability distributions.
And allows flexible extensions using other `R` packages that adhere to conventions, such as `extraDistr`.
Further, by using `alist`, users can specify their own custom distributions (see below in [creating custom margins](#custom-margins)).

It is a bit inconvenient to have to fill in the parameter values manually each time, so we provide a convenience function `mlist` which behaves similarly to `alist`, except that it will evaluate the right hand side of argument values within the list.
This is intended to help when scaling up your code to high dimensions when many marginals to specify.

```{r ch030-margins-mlist, echo=TRUE}
margins <- mlist(
  qnorm(mean = mean(df$Temp), sd = sd(df$Temp)),
  qlnorm(meanlog = mle_mean(df$Ozone), sdlog = mle_sd(df$Ozone))
)
margins
```

*Specifying correlation*.
As mentioned, the user must decide how to describe correlation, based on the particulars of the problem.
For non-normal data and for improved simulation accuracy in our scheme, we advocate the use of rank-based correlations Spearman's $\rho_S$ and Kendall's $\tau$.
But we also support approximate Pearson correlation coefficient matching, while cautioning the user to check the performance for their parametric multivariate model (see [Monte Carlo evaluations](#simulations) for evaluation strategies and guidance).
To aid in correlation specification, and estimation in general, we provide a high-performance function `bigsimr::cor_fast` which estimates Pearson, Spearman, or Kendall correlation using the fastest methods available.
(Anyone who has tried estimating Kendall's $\tau$ using `stats::cor` can attest that the routine does not scale to even moderate dimensions).
Notably, these estimation methods are the standard approaches, not designed specifically designed for high-dimensional correlation estimation (see [Conclusion and Discussion]({#discussion) for more on this).

```{r ch030-aq-cor, echo=TRUE}
type <- 'spearman'
(rho <- cor_fast(df, method = "spearman"))
```

*Checking the theoretical correlation bounds*
As discussed in Section \@ref(background), given a pair of marginal distributions the possible correlations are not free to vary between $[-1, 1]$. 
To ensure that the simulation is not configured to impossible settings, we provide the `bigsimr::cor_bounds` function provides MC estimated theoretical lower and upper bounds (using the Generate, Sort, and Correlate algorithm of @DH2011).

```{r ch030-cor-bounds, echo=TRUE}
cor_bounds(margins = margins, type = type)
```

Since our estimated Spearman correlation $\hat{ \rho}_S$ is within the theoretical bounds, the correlation is valid as input to `bigsimr:rvec`.
By comparison, the Pearson correlation $\rho_P$ is restricted to [-0.8648, 0.8727] for these margins (see `bigsimr::cor_bounds`output below).

```{r ch030-cor-bounds-pearson, echo=TRUE}
cor_bounds(margins = margins, type = 'pearson')
```

*Simulating random vectors*.
Finally, we arrive at the main function of `bigsimr`, `rvec`.
Let's now simulate $B=10,000$ random vectors from the assumed joint distribution of Ozone levels and Temp.

```{r ch030-sim-margins, echo=TRUE}
x <- rvec(10000, rho, margins, type)
df_sim <- as.data.frame(x)
colnames(df_sim) <- colnames(df)
```

Figure \@ref(fig:ch030-plot-sim) plots the 10,000 simulated points.

```{r ch030-plot-sim, fig.cap="Contour plot and marginal densities for the simulated bivariate distribution of Air Quality Temperatures and Ozone levels. The simulated points mimic the observed data with respect to both the marginal characteristics and bivariate association."}
p1 <- df_sim %>%
  ggplot(aes(Temp, Ozone)) +
  geom_density_2d_filled() +
  theme(legend.position = "none") +
  labs(x = "Simulated Temperature", y = "Simulated Ozone") +
  scale_y_continuous(limits = c(0, max(df$Ozone))) +
  scale_x_continuous(limits = range(df$Temp))

p1Temp <- ggplot(df_sim, aes(Temp)) + 
  geom_density(alpha = 0.5, fill = "lightseagreen") +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())

p1Ozone <- ggplot(df_sim, aes(Ozone)) + 
  geom_density(alpha = 0.5, fill = "lightseagreen") + 
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank()) +
  coord_flip() 

p1Temp + plot_spacer() + p1 + p1Ozone + 
  plot_layout(widths = c(3,1), heights = c(1, 3))
```

<!-- 
*Comparison to Uncorrelated Samples*.
We can compare the bivariate distribution above to one where no correlation is taken into account.

```{r ch030-compare-uncorrelated, eval=FALSE}
df_sim2 <- data.frame(
  Temp = rnorm(10000, mean(df$Temp), sd(df$Temp)),
  Ozone = rlnorm(10000, mle_mean(df$Ozone), mle_sd(df$Ozone))
)

p2 <- df_sim2 %>%
  ggplot(aes(Temp, Ozone)) +
  geom_density_2d_filled() +
  theme(legend.position = "none") +
  labs(x = "Temperature", y = "Ozone") +
  scale_y_continuous(limits = c(0, max(df$Ozone))) +
  scale_x_continuous(limits = range(df$Temp))

p2Temp <- ggplot(df_sim2, aes(Temp)) + 
  geom_density(alpha = 0.5, fill = "lightseagreen") +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())

p2Ozone <- ggplot(df_sim2, aes(Ozone)) + 
  geom_density(alpha = 0.5, fill = "lightseagreen") + 
  theme(axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank()) +
  coord_flip() 

p2Temp + plot_spacer() + p2 + p2Ozone + 
  plot_layout(widths = c(3,1), heights = c(1, 3))
```

Notice that this uncorrelated bivariate distribution has the same marginal distributions as the correlated example above.

your comment -->

## Advanced use {#advanced-use}

*Creating a custom marginal distribution*.
Because `bigsimr` uses an `alist` to store the margins, any probability distribution with a well-defined inverse CDF can be used including custom marginal distributions not provided in base `R`. 
Therefore, to specify a marginal distribution absent from an existing package, the user needs to provide a closed-form expression to form the corresponding quantile function.

It is important to follow `R`'s naming convention for probability distributions.
Users should prefix distributions with `r` and `q` for *random* and *quantile* respectively.
Only the quantile function is necessary to simulate random vectors, but to compute the theoretical correlation bounds, it is required to supply univariate random number generator as well.

For an example, let's provide a custom *Pareto* distribution for use with `bigsimr`.
The Pareto CDF is 

$$
F(x) = 1 - \left(\frac{x_m}{x}\right)^\alpha
$$

for scale $x_m > 0$ and shape $\alpha > 0$, with support $x \in \left[x_m, \infty\right)$.
From the CDF, we compute the inverse CDF

$$
F^{-1}(p) = \frac{x_m}{\left(1 - p\right)^{1/\alpha}}
$$

Next we define the Pareto quantile function in R:

```{r ch030-define-qpareto, echo=TRUE}
qpareto <- function(p, scale, shape) {
  scale / (1 - p)^(1/shape)
}
```

Writing random number generating function for our target marginal can be accomplished by calling the quantile function on a uniformly distributed random variable (the inverse transform method @Rizzo2007).

```{r ch030-define-rpareto, echo=TRUE}
rpareto <- function(n, scale, shape) {
  qpareto(runif(n), scale, shape)
}
```

Now with the `qpareto` and `rpareto` functions, we can use the distribution in `bigsimr` just like the other built-in distributions.

```{r ch030-cust-dist-example, echo=TRUE, eval=FALSE}
margins <- alist(
  qnorm(mean = 3.14, sd = 0.1),
  qbeta(shape1 = 1, shape2 = 4),
  qnbinom(size = 10, prob = 0.75),
  qpareto(scale = 1.11, shape = 5.55)
)
cor_bounds(margins, "pearson")
rho <- cor_randPD(4)
x <- rvec(10, rho, margins)
```

*Using `bigsimr` on a computing cluster via `rslurm`*.
Though `bigsimr` runs quickly, at large $d$ users may want to run jobs on a shared computing server.
The R package `rslurm` makes it easy to run embarrassingly large parallel `rvec` calls.
This example assumes that `bigsimr` is installed on a system with a slurm scheduler installed.
A single run of `bigsimr:rvec` using `rslurm` can be code as:

```{r ch030-rvecRslurm-with-comments, echo=FALSE, eval=FALSE}
library(rslurm)
## a single call of rvec
## had to edit rslurm/templates/submit_single_sh.txt
## source ~/.bashrc
## conda activate bigsimr
## conda env config vars list
sjob <- slurm_call(rvec, jobname = 'rvec',
                   list(n=1e6,
                        rho = rho,
                        margins = margins,
                        type = "spearman"),
                   submit = TRUE)
```

```{r ch030-rvecRslurm, echo=TRUE, eval=FALSE}
library(rslurm)
sjob <- slurm_call(rvec, jobname = 'rvec',
                   alist(n=1e6,
                         rho = rho,
                        margins = margins,
                        type = "spearman"),
                   submit = TRUE)
```

<!-- 
Once your jobs complete, `rslurm` conveniently stores simulation results in a standardized format.
Retriving the data is accomplished by
-->

```{r ch030-rvecRslurmRes, echo=FALSE, eval=FALSE}
res <- readRDS(file.path('_rslurm_rvec', list.files('_rslurm_rvec', 'results')))
head(res, 3)
```

Now, let's show off the real power of combining `bigsimr` and `rslurm` by simulating many correlation structures.
The `rslurm::slumr_map` syntax mirrors the `base::lapply` and `purrr::map` functions. 

```{r ch030-rvecRslurmMap-comments, echo=FALSE, eval=FALSE}
library(rslurm)
## a single call of rvec
## had to edit rslurm/templates/submit_sh.txt
## source ~/.bashrc
## conda activate bigsimr
## conda env config vars list
set.seed(06202020)
simReps <- 100
rhoList <- replicate( n = simReps, bigsimr::cor_randPSD(d = length(margins)),
                     simplify=FALSE )
sjob <- slurm_map(x = rhoList,
                  f = rvec,
                  jobname = 'rvecMap',
                  n=1e6,
                  margins = margins,
                  type = "spearman",
                  nodes = 4,
                  cpus_per_node = 4,
                  submit = TRUE)

```

```{r ch030-rvecRslurmMap, echo=TRUE, eval=FALSE}
library(rslurm)
simReps <- 100
rhoList <- replicate( n = simReps, bigsimr::cor_randPSD(d = length(margins)),
                     simplify=FALSE )
sjob <- slurm_map(x = rhoList,
                  f = rvec,
                  jobname = 'rvecMap',
                  n=1e6,
                  margins = margins,
                  type = "spearman",
                  nodes = 4,
                  cpus_per_node = 4,
                  cores = 4,
                  submit = TRUE)
```

On a cluster carrying 24 nodes with 48 threads, these 100 jobs completed in about a minute.

<!-- 
Let's evaluate the quality of simulation performance.

your comment -->

```{r ch030-rvecRslurmMapRes, echo=FALSE, eval=FALSE}
list.files('_rslurm_rvecMap', 'results')
res <- rslurm::get_slurm_out(sjob, outtype = 'raw')
rhoHats <- lapply( res, bigsimr::fastCor, method = 'spearman' )
resData <- NULL
simreps <- length(rhoHats)
for (i in 1:simreps){
    tmpRhoHat <- rhoHats[[i]]
    ## average together
    margins
    avgRhoHat <- tmpRhoHat[lower.tri(tmpRhoHat)]
    tmpPair <- paste0( "pair", apply( combn(x = length(margins), 2), 2, paste, collapse = "_" ) )
    tmpResData <- data.frame( simNum=i, rho=rhoList[[i]][1,2], rhoHat=tmpRhoHat[lower.tri(tmpRhoHat)], pair=tmpPair )
    resData <- rbind(resData, tmpResData)
}
## "wrangle" into a tibble
library(tidyverse)
res <- as_tibble(resData)
## save for viz
saveRDS( res, file = 'data/rvecRslurmMapRes.rds' )
## cleanup careful this deletes output also
## cleanup_files(sjob) 
```

```{r ch030-rvecRslurmMapFig, echo = FALSE, eval=FALSE, message=FALSE, warning=FALSE, out.width= '75%', fig.align='center', fig.cap='The continous marginal pairs exact reproduce the specified correlation whereas the discrete pairs (green nad blue) show a downward bias. Future work with employ a discrete adjusted procedures using *rescaling* on the traditional correlation coefficient.'}
res <- readRDS( 'data/rvecRslurmMapRes.rds' )
res
res %>%
    ggplot( aes( x = rho, y = rhoHat, color = pair ) )  +
    geom_point() +
    geom_abline( slope = 1, intercept = 0 )
```
