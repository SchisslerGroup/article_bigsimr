# Simulation algorithm

## Algorithm description

This section describes the method for simulating a random vector $\bf Y$ with $Y_i$ components for $i=1,2,\ldots,d$. Each $Y_i$ has a specified marginal
distribution function $F_i$ and its inverse. To characterize dependency, every pair $(Y_i, Y_j)$ has either a specified Pearson correlation \@ref(eq:pearson), (rescaled) Spearman correlation \@ref(eq:spearmanRescaled) , or Kendall's $\tau$ (Equation \@ref(eq:tau) ). The method only approximately matches the Pearson correlation in general, whereas the rank-based methods are exact.

The method is best understand as a **parallelized Gaussian copula** (see Equation \@ref(eq:gauss). We shall see that constructing continuous joint distributions that match a target Spearman or Kendall's correlations computes easily when employing Gaussian copulas, since this measures are invariant under the monotone transformations involved [refs]. To do this, we take advantage of a closed form relationship [ref?] between Kendall's $\tau$ and Pearson's correlation coefficient for bivariate normal random variables:

\begin{equation}
(\#eq:convertKendall)
r_{Pearson} = sin \left( \tau_{Kendall} \times \frac{\pi}{2} \right), 
\end{equation}

\noindent and similarly for Spearman's $\rho$ [@K58],

\begin{equation}
(\#eq:convertSpearman)
\rho_{Pearson} = 2 \times sin \left( \rho_{Spearman} \times \frac{\pi}{6} \right).
\end{equation}

For discrete marginals, achieving a target Spearman correlation under this scheme is possible by using components from Equation \@ref(eq:spearmanRescaled) to further adjust the input correlation matrix. Let the unscaled Spearman correlation coefficients be $\rho_{s} \left(Y_{i}, Y_{i^\prime}\right)$ for two marginal distributions and divide the target correlation by the product in the denominator of Equation \@ref(eq:spearmanRescaled). Let these adjustment factors be denoted as $a_i = \left[ 1 - \sum_y p_i(y)^3 \right]^{1/2}$ and specifically rescale the target Spearman correlation matrix by

\begin{equation}
(\#eq:convertSpearmanDiscrete)
\rho_{rs} \left(Y_{i}, Y_{i^\prime}\right) = \frac{\rho_{s} \left(Y_{i}, Y_{i^\prime}\right)}{a_i \times a_{i^\prime}}.
\end{equation}

In a similar fashion, we rescale Kendall's $\tau$ to adjust the input correlation matrix. The conversion formula is given by

\begin{equation}
(\#eq:convertKendallDiscrete)
\rho_{rs} \left(Y_{i}, Y_{i^\prime}\right) = \frac{\rho_{s} \left(Y_{i}, Y_{i^\prime}\right)}{a_i \times a_{i^\prime}}.
\end{equation}

In contrast the rank-based correlations, matching specified Pearson correlation coefficients exactly is computational intense in this scheme. In general, there is no closed form correspondence and involving computing or approximating $\binom{d}{2}$ integrals of the form $EY_iY_j = \int \int y_i y_j f_{X|r}(F_i^{-1}(\Phi(z_i)), F_j^{-1}(\Phi(z_j))dy_idy_j$, for $i,j=1,2,\ldots,d$. For accurate numeric approximation of these integrals, the functions must be evaluated hundreds of times. Others have used efficient Monte Carlo integration schemes (see @Chen2001), but scale poorly to large dimension in reasonable times (property **S2**). Despite all this, if one does desire to characterize dependency using Pearson correlations, we often see in practice --- and it is theoretically justified under certain conditions (@Song00) --- that simply using the target Pearson correlation matrix as the initial conditions to our proposed algorithm will lead to approximate matching in the resultant distribution.

## Simulation Algorithm

Putting the together the facts provided in the equations above, we come the following proposed simulation algorithm to produce a random vector ${\bf Y}$ with specified Spearman's correlation and marginal distributions. Note that all computational steps can be parallelized as each operation can be done or either the $d$ marginals or the $\binom{d}{2}$ pairs for the correlation values. Even the generation of multivariate normal random vectors is parallelized through optimized matrix multiplication/decomposition routines. 

### Inputs
(1) Marginal characteristics including the same of distributional family and parameter values, denotes as $F_i$ for marginal component random variable $Y_i$ for $i=1,\ldots,d$.
(2) A target (specified) Spearman's correlation matrix ${\bf R_{Spearman}}$ with
each $\rho_{Spearman}$ within the Frechet limits. Alternatively, the rescaled
Spearman's correlation (see Equation \@ref(eq:convertKendallDiscrete) ) can be provided.
(3) An error tolerance $\epsilon$ for finding the nearest positive definite matrix a transformed correlation matrix (see step iii below). Alternatively, a maximum number of iterations can be supplied.

### Algorithm
(i) Compute Spearman's $\rho_{rs}$ (see Equation
\@ref(eq:convertKendallDiscrete)) from the specified $\rho_{spearman}$ for each
pair of marginal random variables $(Y_i,Y_{i^\prime})$ with $i \neq i^\prime$
when either marginal is discrete. In such large scale computations, it may be
that numerically $\rho_{rs}$ is be larger/smaller than the Frechet bounds (or
even $\pm 1$). To guard against this, set $\rho_{rs} = min( \rho_{rs}, M)$,
where $M$ is the upper Frechet bound (see [Section Introduction]) and similarly set $\rho_{rs} = max( \rho_{rs}, W)$, where $W$ is the lower Frechet bound for this pair of distributions. Gather these $\rho_{rs} \lq s$ into a new input correlation matrix ${\bf R_{rs}}$.  
(ii) Convert ${\bf R_{Spearman}}$ into ${\bf R_{Pearson}}$ via $\rho_{Pearson} = 2 \times sin \left( \rho_{rs} \times \frac{\pi}{6} \right)$.   
(iii) Finally, ensure that ${\bf R_{Pearson}}$ is positive definite, by finding the nearest positive definite correlation matrix ${\bf R}$ --- using the `R` routine `nearPD` in the `Matrix` package --- within an error tolerance of $\epsilon$.  
(iv) Generate ${\bf X}=(X_1, \ldots, X_d) \sim N_d({\bf 0}, {\bf R})$;  
(v) Transform ${\bf X}$ to ${\bf U} = (U_1, \ldots,  U_d)$ viz $U_i=\Phi(X_i)$, $i=1, \ldots, d$;  
(vi) Return ${\bf Y}  = (Y_1, \ldots,  Y_d)$, where $Y_i=F_i^{-1}(U_i)$, $i=1, \ldots, d$;  
