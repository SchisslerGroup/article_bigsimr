# RNA-seq data applications  {#examples}


```{r ch050-LoadLib, include=FALSE, cache=FALSE}
box::use(
  dplyr[...],
  ggplot2[...],
  GGally[ggpairs, wrap],
  patchwork[...],
  bigsimr[...],
  knitr[include_graphics],
  JuliaCall[julia_call],
  ./R/utils[mom_nbinom]
)
load("data/example_brca.rda")
load("data/example_genes.rda")
sim_nbinom <- readRDS("results/brca_1000_sim.rds")
simRho <- readRDS("results/brca_1000_frobenius.rds")

Sys.setenv(JULIA_NUM_THREADS = parallel::detectCores())
bs <- bigsimr_setup(pkg_check = FALSE)
dist <- distributions_setup()
```


This section demonstrates how to simulate multivariate data using `bigsimr`, aiming to replicate the structure of high-dimensional dependent count data. In an illustration of our proposed methodology, we seek to simulate RNA-sequencing data by producing simulated random vectors mimicking the observed data and its generating process. Modeling RNA-seq using multivariate probability distributions is natural as inter-gene correlation is an inherent part of biological processes [@Wang2009b]. And yet, many models do not account for this, leading to major disruptions to the operating characteristics of statistical estimation, testing, and prediction. See @Efron2012 for a detailed discussion with related methods and @Wu2012b, @Schissler2018; @Schissler2019 for applied examples. The following subsections apply `bigsimr`'s methods to real RNA-seq data, including replicating an estimated parametric structure, MC probability estimation, and MC evaluation of correlation estimation efficiency.

## Simulating High-Dimensional RNA-seq data


```{r ch050-readBRCA, cache=FALSE}
d <- 1000
brca1000 <- example_brca %>%
  select(all_of(1:d)) %>%
  mutate(across(everything(), as.double))
```


We begin by estimating the structure of the TCGA BRCA RNA-seq data set (see [Background](background)). Ultimately, we will simulate $B=10,000$ random vectors ${\bf Y}=(Y_1, \ldots, Y_d)^\top$ with $d=`r d`$. We assume a multivariate negative binomial (MVNB) model as RNA-seq counts are often over-dispersed and correlated. Since all $d$ selected genes exhibit over-dispersion (data not shown), we proceed to estimate the NB parameters $(r_i, p_i), i=1,\ldots,d$, to determine the target marginal PMFs $f_i$. To complete specification of the simulation algorithm inputs, we estimate the Spearman correlation matrix ${ \bf R}_{S}$ to characterize dependency.


With this goal in mind, we first estimate the desired correlation matrix using the fast implementation provided by `bigsimr`:


```{r ch050-estRhoBRCA, echo=TRUE, cache=FALSE}
# Estimate Spearman's correlation on the count data
R_S <- bs$cor(as.matrix(brca1000), bs$Spearman)
```


Next, we estimate the marginal parameters. We use the method of moments (MoM) to estimate the marginal parameters for the multivariate negative binomial model. While, marginal distributions are from the same probability family (NB), they are heterogeneous in terms of the parameters probability and size $(p_i, n_i)$ for $i,\ldots,d$. The functions below support this estimation for later use in `rvec`.


```{r ch050-nbHelpers, echo=TRUE}
make_nbinom_margins <- function(sizes, probs) {
  margins <- lapply(1:length(sizes), function(i) {
    dist$NegativeBinomial(sizes[i], probs[i])
  })
  do.call(c, margins)
}
```


We apply these estimators to all `r d` genes across the `r nrow(brca1000)` patients:


```{r ch050-estMargins, echo=TRUE}
nbinom_fit <- apply(brca1000, 2, mom_nbinom)
sizes <- nbinom_fit["size",]
probs <- nbinom_fit["prob",]
nb_margins <- make_nbinom_margins(sizes, probs)
```


Notably, the estimated marginal NB probabilities $\{ \hat{p}_i \}$ are small --- ranging in the interval $[`r min(probs)` , `r max(probs)`]$. This gives rise to highly variable counts and, typically, less restriction on potential pairwise correlation pairs. Once the functions are defined/executed to complete marginal estimation, we specify targets and generate the desired random vectors using `rvec`. Now we check admissibility of specified correlation matrix.


```{r ch050-cor-check, echo=TRUE}
# 1. Mapping step first
R_X <- bs$cor_convert(R_S, bs$Spearman, bs$Pearson)
# 2a. Check admissibility
(is_valid_corr <- bs$iscorrelation(R_X))
# 2b. compute nearest correlation
if (!is_valid_corr) {
  R_X_pd <- bs$cor_nearPD(R_X)
  ## Quantify the error
  targets      <- R_X[lower.tri(R_X, diag = FALSE)]
  approximates <- R_X_pd[lower.tri(R_X_pd, diag = FALSE)]
  R_X          <- R_X_pd
}
summary(abs(targets - approximates))
```


While the exact $d \times d$ Spearman correlation matrix is not strictly admissible in our scheme (as seen by the non-positive definite result above), the approximation is close with a maximum absolute error of `r max( abs(targets - approximates))` and average absolute error of `r mean(abs(targets - approximates))` across the `r choose(d,2)` correlations.


```{r ch050-runBRCA-echo, echo=TRUE, eval=FALSE}
sim_nbinom <- bs$rvec(10000, R_X, nb_margins) 
colnames(sim_nbinom) <- colnames(brca1000)
```


Figure \@ref(fig:ch050-simDataFig) displays the simulated counts and pairwise relationships for our example genes from Table \@ref(tab:ch010-realDataTab).
Simulated counts roughly mimic the observed data but with a smoother appearance due to the assumed parametric form and with less extreme points then the observed data in Figure \@ref(fig:ch010-realDataFig). Figure \@ref(fig:ch050-figBRCA) displays the aggregated results of our simulation by comparing the specified target parameter (horizontal axes) with the corresponding quantities estimated from the simulated data (vertical axes). The evaluation shows that the simulated counts approximately match the target parameters and exhibit the full range of estimated correlation from the data.

```{r ch050-simDataFig, cache=FALSE, fig.cap="Simulated data for three selected high-expressing genes generally replicates the estimated data structure. The data do not exhibit outlying points, but do possess the desired Spearman correlations, central tendencies, and discrete values."}
set.seed(2020-02-25)
num_genes <- 3
gene_sample <- sample(example_genes[1:1000], num_genes)

ggpairs(data = as.data.frame(sim_nbinom[, gene_sample]),
        upper = list(continuous = wrap('cor', method = "spearman"))) + 
  theme_bw()
```

```{r ch050-figBRCA, out.width='80%', fig.cap="Simulated random vectors from a multivariate negative binomial replicate the estimated structure from an RNA-seq data set. The dashed red lines indicate equality between estimated parameters from simulated data (vertical axes) and the specified target parameters (horizontal axes)."}
include_graphics('fig/ch050-figBRCA.png')
```

*Limitations, conclusions, and recommendations*

The results show overall good simulation performance for our choice of parameters settings. Our settings were motivated by modeling high-expressing genes from TCGA BRCA data set. In general, the ability to match marginal and dependence parameters depends on the particular joint probability model. We recommend to evaluate and tune your simulation until you can be assured of the accuracy.


## Simulation-based joint probability calculations


Many statistical tasks require evaluation of a joint probability mass (or density) function:


$$
P( {\bf Y} = {\bf y} ), \: y_i \in \chi_i.
$$


where $\chi_i$ is the sample space for the $i^{th}$ component of the random vector $\bf{Y}$. Compact representations with convenient computational forms are rare for high-dimensional constructions, especially with heterogeneous, correlated marginal distributions (or margins of mixed data types). Given a large number of simulated vectors as produced above, estimated probabilities are readily given by counting the proportion of simulated vectors meeting the desired condition. In our motivating application, one may ask what is the probability that all genes expressed greater than a certain threshold value ${ \bf y}_0$. This can be estimated as 


$$
\hat{P}( {\bf Y} \ge {\bf y_0 } ) = \frac{1}{B} \sum_{b=1}^B I( {\bf Y}^{ (b) } \ge {\bf y_0 } ),
$$


```{r ch050-densityEvaluation, include=FALSE}
d <- ncol(sim_nbinom)
B <- nrow(sim_nbinom)
y0 <- 1
pHat <- mean(apply(sim_nbinom, 1, function(Y) {
  all(Y >= y0)
}))
```


where ${\bf Y}^{(b)} $ is the $b^{th}$ simulated vector from a total of $B$ simulation replicates and $I(\cdot)$ is the indicator function. For example, we can estimate from our $B=10,000$ simulated vectors that the probability of all genes expressing (i.e., ${\bf y}_i \geq 1, \forall \; i$) is $`r pHat`$.


```{r ch050-densityEvaluationECHO, echo=TRUE}
<<ch050-densityEvaluation>>
pHat
```


## Evaluation of correlation estimation efficiency


MC methods are routinely used in many statistical inferential tasks including estimation, hypothesis testing, error rates, and empirical interval coverage rates. To conclude the example applications, we demonstrate how `bigsimr` can be used to evaluate estimation efficiency. In particular, we wish to assess the error in our correlation estimation above. We used a conventional method, based on classical statistical theory which was not designed for high-dimensional data. Indeed, high-dimensional covariance estimation (and precision matrices) is an active area of statistical science, .e.g., [@Won2013g; @VanWieringen2016].

In this small example, we simulate $m=30$ data sets with the number of simulated vectors matching the number of patients in the BRCA data set, $N=`r nrow(example_brca)`$. Since our simulation is much faster for the Pearson correlation type (see Figure \@ref(fig:ch040-largeDfig)), we only convert the Spearman correlation matrix once (and ensure it is positive definite). At each iteration, we estimate the quadratic loss (residual sum of squared errors) from the specified ${\bf R}_{S}$, producing a distribution of loss values.


```{r ch050-quadlossECHO, echo=TRUE, eval=FALSE}
# Simulate random vectors equal to the sample size
N <- nrow(example_brca)
# create m random vectors and estimate correlation
simRho <- replicate(n = m, expr = {
  tmpSim <- bs$rvec(N , R_X, nb_margins)
  bs$cor(tmpSim, bs$Spearman)
}, simplify = FALSE)
# Evaluate the residual sum of squared error
sapply(simRho, function(R) sum((R - R_S)^2))
```


```{r ch050-lossResults}
frobenius_loss <- sapply(simRho, function(R) sum((R - R_S)^2))
```


The `R` summary function supplies the mean-augmented five-number summary of the quadratic loss distribution computed above.


```{r ch050-loss-summary, echo=TRUE}
summary(frobenius_loss)
```


This distribution could be compared to high-dimensional designed covariance estimators for guidance on whether the additional complexity and computation time are warranted.
